{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sklearn as sklearn\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import cv\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split,  StratifiedShuffleSplit\n",
    "from sklearn.ensemble import GradientBoostingClassifier, \\\n",
    "                            RandomForestClassifier,\\\n",
    "                            GradientBoostingRegressor,\\\n",
    "                            RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.inspection.partial_dependence import partial_dependence, plot_partial_dependence\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold,KFold\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#https://www.pythonpool.com/check-if-number-is-prime-in-python/\n",
    "\n",
    "#Inputs: num - a number you want to check if it is prime \n",
    "#outputs: Ture or false epending if it is prime or not \n",
    "def isprime(num):\n",
    "    for n in range(2,int(num**1/2)+1):\n",
    "        if num%n==0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "#https://gist.github.com/iansan5653/1e306da9688d85934385b266e74f153a\n",
    "\n",
    "#Inputs: c- takes in an int\n",
    "#outputs: [b,a] - the closest two factors for the factorization of a given number\n",
    "def calc_closest_factors(c: int):\n",
    "    if c//1 != c:\n",
    "        raise TypeError(\"c must be an integer.\")\n",
    "    if c>=5:\n",
    "        if isprime(c)==True:\n",
    "            c=c+1\n",
    "    \n",
    "    a, b, i = 1, c, 0\n",
    "    while a < b:\n",
    "        i += 1\n",
    "        if c % i == 0:\n",
    "            a = i\n",
    "            b = c//a\n",
    "    \n",
    "    return [b, a]\n",
    "\n",
    "\n",
    "#Purpose:Return and aggregated dataframe based on a given index,aggregation_value,and aggregation_calculation\n",
    "#Input:\n",
    "    #df - dataframe you wish to aggregate \n",
    "    #agg_value- value you wish to aggreate\n",
    "    #index - group by index, can be a string or an array\n",
    "    #agg_calc - aggreagte calculation you wish to preform, can be a string or an array\n",
    "#output:\n",
    "    #df - returns the new aggregate dataframe \n",
    "def get_aggCalc(df,agg_value,index,agg_calc):\n",
    "        if type(index)==str:\n",
    "            index = [index]\n",
    "        df_filter = index.copy()\n",
    "        df_filter.append(agg_value)\n",
    "        df= df.groupby(index).agg({agg_value:agg_calc}).reset_index()\n",
    "        if type(agg_calc)==list:\n",
    "            df.columns = ['_'.join(col) for col in df.columns.values]\n",
    "            df.columns = [col.split('_')[0] if col.split('_')[1]=='' else col for col in df.columns ]\n",
    "        else:\n",
    "            df = df.rename(columns = {agg_value:agg_value+\"_\"+agg_calc})\n",
    "        return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is a lot bigger. So for a lot of the questions on the homework, we are asked to plot two features, segmented out by another. This function does this for us, but with a lot of given flexibility. It is super helpful when testing out interactions between three variables. There are some adjustments we plan to make to make it more consistent (i.e., for the aggregate plots, we choose seaborn sometimes rather than matplotlib. This was becuase we found seaborn made it easier to fit our data as it didn't require special pivoting.)\n",
    "\n",
    "So let's go over every input variable here and there expected typing.\n",
    "\n",
    "* **df**: DataFrame - dataframe with all your data\n",
    "* **decompose**: string - factor you wish to separate the relationship for. For example, if you wanted to see how bike rentals change by hour and season, you would set this to season.\n",
    "* **xfeature**: string - this will be your x variable on the final plots.\n",
    "* **yfeature**: string - this will be your y variable on the final plots. It's our dependent variable.\n",
    "* **agg_choice**: string - which forms of aggregation do you want to use. Note this only supports one value right now, although it could be expanded to include a list.\n",
    "* **Overlay**: Boolean - If you want to put all graphs on a single plot rather than individual subplots. Useful when trying to directly compare\n",
    "* **plt_choice**: string - This will let the algorithm know what type of plot you want. For now, the following are supported.\n",
    " * scattter - scatter plot\n",
    " * scatter_agg - scatter plot, but taking an aggregate based on agg_choice to make only one point per xfeature value\n",
    " * line - line graph, this will automatically aggregate based on agg_choice, otherwise, it's too messy\n",
    " * bar - bar graph, this will automatically aggregate based on agg_choice otherwise, it's too messy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_effect_on_two(df,decompose,xfeature,yfeature,plt_choice='scatter',agg_choice='mean',figsize_factor=1,overlay=False):\n",
    "    x_list = df[decompose].unique()\n",
    "    x_count = len(x_list)\n",
    "    plt_x,plt_y = calc_closest_factors(x_count)\n",
    "    if overlay == False:\n",
    "        fig,ax = plt.subplots(plt_x,plt_y,figsize=(plt_y*4*figsize_factor, plt_x*4*figsize_factor))\n",
    "        fig.tight_layout()\n",
    "        plt_index = 1\n",
    "        for x in x_list:\n",
    "            plt.subplot(plt_x,plt_y,plt_index)\n",
    "            df_split = df[df[decompose]==x]\n",
    "            if plt_choice == 'scatter':\n",
    "                plt.scatter(y=df_split[yfeature],x=df_split[xfeature])\n",
    "            elif plt_choice =='box':\n",
    "                sns.boxplot(x=df_split[xfeature],y=df_split[yfeature])\n",
    "            else:\n",
    "                agg_df = get_aggCalc(df,yfeature,xfeature,agg_choice)\n",
    "                if plt_choice =='bar':\n",
    "                    plt.bar(x = agg_df[xfeature],height=agg_df[yfeature+\"_\"+agg_choice])\n",
    "                elif plt_choice =='line':\n",
    "                    plt.plot(agg_df[yfeature+\"_\"+agg_choice])\n",
    "                elif plt_choice =='scatter_agg':\n",
    "                    plt.scatter(x = agg_df[xfeature],y=agg_df[yfeature+\"_\"+agg_choice])\n",
    "            plt.xlabel(xfeature)\n",
    "            plt.ylabel(yfeature)\n",
    "            plt.title(x)\n",
    "            plt_index = plt_index +1 \n",
    "        fig.subplots_adjust(hspace=.5)  \n",
    "    else:\n",
    "        fig,ax = plt.subplots(figsize=(plt_y*4, plt_x*4))\n",
    "        fig.tight_layout()\n",
    "        if plt_choice == 'scatter':\n",
    "            sns.scatterplot(data=df,y=yfeature,x=xfeature,hue=decompose)\n",
    "            #plt.colorbar()\n",
    "        elif plt_choice =='box':\n",
    "                sns.boxplot(x=df[xfeature],y=df[yfeature],hue=df[decompose])\n",
    "        else:\n",
    "            agg_df = get_aggCalc(df,yfeature,index = [xfeature,decompose], agg_calc=agg_choice)\n",
    "            if plt_choice =='bar':\n",
    "                agg_df= agg_df.pivot(index=xfeature, columns=decompose, values=yfeature+\"_\"+agg_choice)\n",
    "                agg_df.plot.bar(ax=ax)\n",
    "            elif plt_choice =='line':\n",
    "                sns.lineplot(data=agg_df,x=xfeature,y=yfeature+\"_\"+agg_choice,hue=decompose)\n",
    "            elif plt_choice =='scatter_agg':\n",
    "                 sns.scatterplot(data=agg_df,y=yfeature+\"_\"+agg_choice,x=xfeature,hue=decompose)\n",
    "        plt.xlabel(xfeature)\n",
    "        plt.ylabel(yfeature)\n",
    "        plt.title('overlaid graph for relationship between '+ xfeature + ' on ' + yfeature +' separated by ' + decompose)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very similar to the above, just now with one feature (or an array of feature plotted one by one) against another. added figure_size option to increase size of plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features(df,xfeature_array,yfeature_array,plt_choice='scatter',agg_choice='mean',figsize_factor=1,title=True):\n",
    "    for yfeature in yfeature_array:\n",
    "        x_list = xfeature_array\n",
    "        x_count = len(x_list)\n",
    "        plt_x,plt_y = calc_closest_factors(x_count)\n",
    "        fig,ax = plt.subplots(plt_x,plt_y,figsize=(plt_y*4*figsize_factor, plt_x*4*figsize_factor))\n",
    "        fig.tight_layout()\n",
    "        if title==True:\n",
    "            fig.suptitle('Plotting x features on '+ yfeature, fontsize=16)\n",
    "        fig.subplots_adjust(top=0.8)\n",
    "        plt_index=1\n",
    "        for xfeature in x_list:\n",
    "            plt.subplot(plt_x,plt_y,plt_index)\n",
    "            if plt_choice == 'scatter':\n",
    "                plt.scatter(y=df[yfeature],x=df[xfeature])\n",
    "            elif plt_choice =='box':\n",
    "                sns.boxplot(x=df[xfeature],y=df[yfeature])\n",
    "            else:\n",
    "                agg_df = get_aggCalc(df,yfeature,xfeature,agg_choice)\n",
    "                if plt_choice =='bar':\n",
    "                    plt.bar(x = agg_df[xfeature],height=agg_df[yfeature+\"_\"+agg_choice])\n",
    "                elif plt_choice =='line':\n",
    "                    plt.plot(agg_df[yfeature+\"_\"+agg_choice])\n",
    "                elif plt_choice =='scatter_agg':\n",
    "                    plt.scatter(x = agg_df[xfeature],y=agg_df[yfeature+\"_\"+agg_choice])\n",
    "                \n",
    "            plt.xlabel(xfeature)\n",
    "            plt.ylabel(yfeature)\n",
    "            plt_index = plt_index +1 \n",
    "        fig.subplots_adjust(hspace=.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicating for sake of submission\n",
    "bike_test = pd.read_table('Bike_test.csv',header=0,delimiter=',')\n",
    "bike_train = pd.read_table('Bike_train.csv',header=0,delimiter=',')\n",
    "\n",
    "#copy from above \n",
    "bike_train_modeling = bike_train.copy()\n",
    "bike_test_modeling = bike_test.copy()\n",
    "\n",
    "#Creating data time variable for feature exploration\n",
    "bike_train_modeling['Date'] = pd.to_datetime(bike_train_modeling[['year','month','day']])\n",
    "bike_test_modeling['Date'] = pd.to_datetime(bike_test_modeling[['year','month','day']])\n",
    "\n",
    "#potential relaationship on weekends.  Non working day may tell us the same thing, but i think there are slight differences \n",
    "#that it's not bad to add\n",
    "bike_train_modeling['weekday_number'] = bike_train_modeling['Date'].apply(lambda x: x.weekday())\n",
    "bike_test_modeling['weekday_number'] = bike_test_modeling['Date'].apply(lambda x: x.weekday())\n",
    "\n",
    "\n",
    "#debatable variables for cateogrical transformation: weather - it could be ordinal\n",
    "categorical_variables = ['season','year','weather']\n",
    "\n",
    "#Getting categorical Vairables\n",
    "for cv in categorical_variables:\n",
    "    bike_train_modeling[cv] = bike_train_modeling[cv].astype('category')\n",
    "    bike_test_modeling[cv] = bike_test_modeling[cv].astype('category')\n",
    "#move all ints to floats\"\n",
    "for col in bike_train_modeling.columns:\n",
    "    if bike_train_modeling[col].dtype == 'int64':\n",
    "        bike_train_modeling[col] = bike_train_modeling[col].astype('float64')\n",
    "for col in bike_test_modeling.columns:\n",
    "    if bike_test_modeling[col].dtype == 'int64':\n",
    "        bike_test_modeling[col] = bike_test_modeling[col].astype('float64')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#run encoders\n",
    "variableNames = categorical_variables\n",
    "bike_train_temp_encoded = oneHot_vairables(bike_train_modeling,variableNames)\n",
    "bike_test_temp_encoded = oneHot_vairables(bike_test_modeling,variableNames)\n",
    "bike_train_temp_encoded = cycle_encode(bike_train_temp_encoded,['month','day','hour','weekday_number']) \\\n",
    "                            .drop(['month','day','weekday_number'],axis=1) #using hour will drop hour latter\n",
    "\n",
    "bike_test_temp_encoded = cycle_encode(bike_test_temp_encoded,['month','day','hour','weekday_number']) \\\n",
    "                            .drop(['month','day','weekday_number'],axis=1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    #See Question 1.C \n",
    "    df['peak_riding_time_workingDay'] = df[['hour','workingday']].apply(lambda df: 1 if (df['workingday'] == 1 and \\\n",
    "                                                        (7 <= df['hour'] <= 8  or 17 <= df['hour'] <= 18)) else 0,axis=1) \n",
    "    df['peak_riding_time_nonWorkingDay'] = df[['hour','workingday']].apply(lambda df: 1 if \\\n",
    "                                                        (df['workingday'] == 0 and 10 <= df['hour'] <= 19) else 0,axis=1)\n",
    "    \n",
    "    #we are going to remove atemp, so let's capture that boost we saw during exploration\n",
    "    df['itFeelsHot'] = df['atemp'].apply(lambda x: 1 if x>=30 else 0)\n",
    "    \n",
    "    df['deadHour'] = df['hour'].apply(lambda x: 1 if x==4 else 0) #see above gaphs\n",
    "    df['lowHumidity'] =df['humidity'].apply(lambda x: 1 if x<15 else 0)#see pdp\n",
    "    df['logHumidity'] = df['humidity'].apply(lambda x: 0 if np.log(x+.001)<0 else np.log(x)) #quick log test\n",
    "    df['LHum_HTemp'] = df[['humidity','temp']].apply(lambda df: 1 if (df.humidity>40 and df.temp<10) else 0,axis=1)#intercation  \n",
    "    \n",
    "    return df \n",
    "bike_train_temp_encoded = add_features(bike_train_temp_encoded)\n",
    "bike_test_temp_encoded = add_features(bike_test_temp_encoded)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_Features = ['daylabel', #little predictive power for daylabel plus is captured with month,year,day better\n",
    "                 'windspeed',#already shown to have little importance in above graphs and confirmed with feature importance\n",
    "                 'day_sin', #days play little into the ultimate prediction\n",
    "                 'day_cos',\n",
    "                 'holiday', #could be leading to worse prediction because there are more holidays in the latter half of the \n",
    "                            #month than. we could be undersestimating this power',\n",
    "                 'weather_decent', #not predicitive\n",
    "                 'weather_veryBad',\n",
    "                 'hour', #encoded via clyical data don't want multi-collinearity issues\n",
    "                 'atemp', #multicollinearity issues\n",
    "                 'Date',\n",
    "                 'lowHumidity', #not important\n",
    "                 'logHumidity',\n",
    "                 'LHum_HTemp' #shap Value gave some insights there may be a spike when it's low humidty and high temperature\n",
    "                             # but couldn't find it\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_test_temp_encoded = bike_test_temp_encoded.drop(drop_Features,axis=1)\n",
    "X = bike_train_temp_encoded.drop(['count'],axis=1)\n",
    "X = X.drop(drop_Features,axis=1)\n",
    "y = bike_train_temp_encoded['count']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparamter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    " 'learning_rate' : [.05,.10,.15,.20,.25,.30],\n",
    " 'n_estimators' : [50,100,200,1000],\n",
    " 'max_depth' : [3,4,5,6,7,8,9,10],\n",
    " 'min_child_weight' : [1,2,3,4,5,6],\n",
    " 'gamma': [0,.1,.2,.3,.4,.5,.6],\n",
    " 'colsample_bytree' : [.3,.4, .5,.6,.7 ]\n",
    "\n",
    "}\n",
    "\n",
    "gb_tree = XGBRegressor(seed = 1)\n",
    "\n",
    "rs_cv = RandomizedSearchCV(estimator=gb_tree,\n",
    "                         param_distributions=params,\n",
    "                         scoring='neg_mean_squared_error',\n",
    "                         #verbose=1,\n",
    "                         n_iter= 1000)#change depending on how many fits we want to try. \n",
    "rs_cv.fit(X, y)\n",
    "print(\"Best parameters:\", rs_cv.best_params_)\n",
    "print('Best MSE '+ str(rs_cv.best_score_))\n",
    "best_params_ = rs_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = best_params_\n",
    "gb_tree = XGBRegressor(seed = 1,)\n",
    "gb_tree.set_params(**best_params)\n",
    "gb_tree.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_feature_importance = gb_tree.feature_importances_\n",
    "sorted_index = np.argsort(gb_feature_importance)\n",
    "pos = np.arange(sorted_index.shape[0]) + 0.5\n",
    "fig, ax = plt.subplots(figsize=(12, 20))\n",
    "plt.barh(pos, gb_feature_importance[sorted_index], align=\"center\")\n",
    "plt.yticks(pos, np.array(X.columns)[sorted_index]);\n",
    "plt.title('feature importance for gradient boosting');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = gb_tree.predict(bike_test_temp_encoded)\n",
    "df_final = pd.DataFrame({'count':y_pred_test})\n",
    "df_final = df_final.reset_index()\n",
    "df_final['index'] = df_final['index'] + 1 #correct for difference in indexing \n",
    "df_final.rename(columns={'index':'Id'},inplace=True)\n",
    "\n",
    "#Note: I really want to round this, it just preformed worse. \n",
    "#I hate giving answers that don't make sense in terms of the problem\n",
    "df_final['count'] = df_final['count'].apply(lambda x: 0 if x<0 else x) \n",
    "df_final.to_csv('sampleSubmission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
